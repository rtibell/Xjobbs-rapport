\texttt{ToDo: Elaboration about discussions and future work}
During this work a number of ides regarding improvements has been born and scrutinized. Some of these are discussed here in the final section of the apaer.

\subsection{Improving the feature space}\label{discuss_improve_feature}
A variety of information sources was used to create the feature set but no Internet based realtors were willing to share there textual descriptions of the apartments sold. This source of information is probably the single most important piece of information needed to make a leap in the quality of the model. Studying the textual descriptions of apartment sales advertising indicates that the realtors use a common jargon when writing these descriptions. Hence the textual description would be partitioned into tokens, from these so called N-grams (the N nearest neighbouring tokens are clustered together) can be constructed. From this list of N-grams the most frequent are selected, each N-gram becomes a feature and is added to the feature set feed into the NLP. This arrangement would hopefully be able to detect some of the more soft (non metric) qualities of the apartment.  

\subsection{Algorithmic improvements}
The regime described in \cite{art}{WilsJoneJenkWare:04} of using a GT to compute a objective function used by a GA to select a preferred feature set that is feed into the MLP constructing the predictive model is probably a good extension of this work that probably can raise the quality of this work. Combining the GT feature selection with the extended feature set discussed in previous section \ref{discuss_improve_feature} is a natural extension of this work. The GT feature selection could be viewed as a pre processing of the feature set and the MLP and GA parameter optimization would take place as mentioned in this paper. 